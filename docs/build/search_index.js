var documenterSearchIndex = {"docs":
[{"location":"api.html#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api.html","page":"API Reference","title":"API Reference","text":"Modules = [SLAM]\nPrivate = true","category":"page"},{"location":"api.html#SLAM.Extractor","page":"API Reference","title":"SLAM.Extractor","text":"Feature extractor.\n\nPerforms Shi-Tomasi feature extraction algorithm with support for masking-out regions in which to avoid feature detection.\n\n\n\n\n\n","category":"type"},{"location":"api.html#SLAM.Frame","page":"API Reference","title":"SLAM.Frame","text":"Frame that encapsulates information of a camera in space at a certain moment.\n\nParameters:\n\nid::Int64: Id of the Frame.\nkfid::Int64: Id of the Frame in the global map, contained in MapManager.   Frames that are in this map are called \"Key-Frames\".\ntime::Float64: Time of the frame at which it was taken on the camera.\ncw::SMatrix{4, 4, Float64, 16}: Transformation matrix [R|t]   that transforms from world to camera space.\nwc::SMatrix{4, 4, Float64, 16}: Transformation matrix [R|t]   that transforms from camera to world space.\ncamera::Camera: Camera associated with this frame.\nright_camera::Camera: In case of stereo, this is the camera   associated with the right frame.\nkeypoints::Dict{Int64, Keypoint}: Map of that this frames observes.\nketpoints_grid::Matrix{Set{Int64}}: Grid, where each cell contains   several keypoints. This is useful when want to retrieve neighbours   for a certain Keypoint.\nnb_occupied_cells::Int64: Number of cells in keypoints_grid that have   at least one Keypoint.\ncell_size::Int64: Cell size in pixels.\nnb_keypoints::Int64: Total number of keypoints in the Frame.\nnb_2d_keypoints::Int64: Total number of 2D keypoints in the Frame.\nnb_3d_keypoints::Int64: Total number of 3D keypoints in the Frame.\nnb_3d_keypoints::Int64: Total number of stereo keypoints in the Frame.\ncovisible_kf::OrderedDict{Int64, Int64}: Dictionary with kfid => score   of ids of Frames that observe the sub-set of size score of keypoints   in Frame.\nlocal_map_ids::Set{Int64}: Set of ids of MapPoints that are not visible   in this Frame, but are a potential candidates for remapping   back into this Frame.\n\n\n\n\n\n","category":"type"},{"location":"api.html#SLAM.FrontEnd","page":"API Reference","title":"SLAM.FrontEnd","text":"Front-End component which is responsible for tracking keypoints and computing poses for the Frames. It also decides when the system needs a new Keyframe added to its map.\n\nParameters:\n\ncurrent_frame::Frame: Current frame that is being processed.   This is a shared Frame between FrontEnd, MapManager, Estimator   and SlamManager.\nmotion_model::MotionModel: Motion model that is used to predict   pose for the Frame before the actual pose for it was computed.\nmap_manager::MapManager: Map manager that is responsible for the   creation of new Keyframes in the map.\nparams::Params: Parameters of the system.\ncurrent_image::Matrix{Gray{Float64}}: Current image that is processed.\nprevious_image::Matrix{Gray{Float64}}: Previous processed image.\ncurrent_pyramid::ImageTracking.LKPyramid: Pre-computed pyramid   that is used for optical flow tracking for the current_image.\nprevious_pyramid::ImageTracking.LKPyramid: Pre-computed pyramid   that is used for optical flow tracking for the previous_image.\n\n\n\n\n\n","category":"type"},{"location":"api.html#SLAM.Keypoint","page":"API Reference","title":"SLAM.Keypoint","text":"Keypoint is a feature in the image used for tracking.\n\nParameters:\n\nid::Int64: Id of the Keypoint.\npixel::Point2f: Pixel coordinate in the image plane in (y, x) format.\nundistorted_pixel::Point2f: In presence of distortion in camera,   this is the undistorted pixel coordinates.\nposition::Point3f: Pre-divided (backprojected) keypoint in camera space.   This is used in algorithms like 5Pt for Essential matrix calculation.\ndescriptor::BitVector: Descriptor of a keypoint.\nis_3d::Bool: If true, then this keypoint was triangulated.\nis_retracked::Bool: If true, then this keypoint was lost   and re-tracked back by match_local_map! method.\nis_stereo::Bool: If true, then this keypoint has left↔right   correspondence for the stereo image.\nright_pixel::Point2f: Pixel coordinate in the right image plane   in (y, x) format.\nright_undistorted_pixel::Point2f: In presence of distortion in camera,   this is the undistorted right_pixel coordinates.\nright_position::Point3f: Pre-divided (backprojected) right keypoint   in camera space. This is used in algorithms like 5Pt   for Essential matrix calculation.\n\n\n\n\n\n","category":"type"},{"location":"api.html#SLAM.MotionModel","page":"API Reference","title":"SLAM.MotionModel","text":"Constant Velocity Motion Model\n\n\n\n\n\n","category":"type"},{"location":"api.html#SLAM.MotionModel-Tuple{StaticArrays.SMatrix{4, 4, Float64, L} where L, Any}","page":"API Reference","title":"SLAM.MotionModel","text":"Apply Motion Model to a given wc transformation.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.add_keyframe!-Tuple{SLAM.MapManager}","page":"API Reference","title":"SLAM.add_keyframe!","text":"Copy current MapManager's Frame and add it to the KeyFrame map. Increase current keyframe id & total number of keyframes.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.backproject-Tuple{Camera, StaticArrays.SVector{2, T} where T}","page":"API Reference","title":"SLAM.backproject","text":"Transform point from 2D to 3D by dividing by K.\n\nArguments:\n\npoint::Point2: Point to backproject in (y, x) format.\n\nReturns:\n\nBackprojected Point3f in (x, y, z = 1.0) format.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.check_new_kf_required-Tuple{SLAM.FrontEnd}","page":"API Reference","title":"SLAM.check_new_kf_required","text":"Check if we need to insert a new KeyFrame into the Map.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.check_ready_for_init!-Tuple{SLAM.FrontEnd}","page":"API Reference","title":"SLAM.check_ready_for_init!","text":"Check if there is enough average rotation compensated parallax between current Frame and previous KeyFrame.\n\nAdditionally, compute Essential matrix using 5-point Ransac algorithm to filter out outliers and check if there is enough inliers to proceed.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.compute_parallax-Tuple{SLAM.FrontEnd, Int64}","page":"API Reference","title":"SLAM.compute_parallax","text":"Compute parallax in pixels between current Frame and the provided current_frame_id Frame.\n\nArguments:\n\ncompensate_rotation::Bool:   Compensate rotation by computing relative rotation between   current Frame and previous Keyframe if true. Default is true.\nonly_2d::Bool: Consider only 2d keypoints. Default is true.\nmedian_parallax::Bool:   Instead of the average, compute median parallax. Default is true.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.compute_pose!-Tuple{SLAM.FrontEnd}","page":"API Reference","title":"SLAM.compute_pose!","text":"Compute pose of a current Frame using P3P Ransac algorithm. Pose is computed from the triangulated Keypoints (MapPoints) that are visible in this frame.\n\nReturns:\n\ntrue if the pose was successfully computed, otherwise false.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.describe-Tuple{SLAM.Extractor, Any, Any}","page":"API Reference","title":"SLAM.describe","text":"Returns:\n\nVector of descriptors of BitVector type and vector of keypoints' coordinates of type CartesianIndex{2}.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.detect-Tuple{SLAM.Extractor, Any, Any}","page":"API Reference","title":"SLAM.detect","text":"Detect keypoints in the image.\n\nArguments:\n\ncurrent_points:   Vector of points, which define circular regions, where to avoid   detecting new features. This can be used to decrease the amount of   similar keypoints. Pass empty vector to skip this step.\nσ::Real:   Standard deviation for the gaussian blur.   This is used to smooth out circles in the mask to reduce the chance   of detecting aliased circle corners. Default value is 3.   Pass 0 to skip this step.\n\nReturns:\n\nKeypoints in the (y, x) format.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.do_local_map_matching-Tuple{SLAM.Mapper, SLAM.Frame, Set{Int64}}","page":"API Reference","title":"SLAM.do_local_map_matching","text":"Given a frame and its local map of Keypoints ids (triangulated), project respective mappoints onto the frame, find surrounding keypoints (triangulated?), match surrounding keypoints with the projection. Best match is the new candidate for replacement.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.fb_tracking!-Tuple{AbstractVector{StaticArrays.SVector{2, Float64}}, ImageTracking.LKPyramid, ImageTracking.LKPyramid, AbstractVector{StaticArrays.SVector{2, Float64}}, ImageTracking.LucasKanade}","page":"API Reference","title":"SLAM.fb_tracking!","text":"Perform Forward-Backward tracking by first tracking keypoints from previous_pyramid to current_pyramid and then track resuling keypoints in reverse order. Then filter out those forward-backward keypoints that are too far away from the original keypoints to be consistent.\n\nArguments:\n\nnew_keypoints:   Vector where to write resulting new poisitions of keypoints.   Should be of the same size as keypoints vector.\nmax_distance::Real:   Maximum distance in pixels between Forward-Backward tracked keypoints   to be considered the same keypoint.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.find_best_match-Tuple{SLAM.MapManager, SLAM.Frame, SLAM.MapPoint, Any, Any}","page":"API Reference","title":"SLAM.find_best_match","text":"For a given target_mp MapPoint, find best match among surrounding keypoints.\n\nGiven target mappoint from covisibility graph, its projection onto frame and surrounding keypoints in frame for that projection, find best matching keypoint (already triangulated?) in frame.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.get_mask-Union{Tuple{T}, Tuple{Matrix{T}, Any, Any}} where T","page":"API Reference","title":"SLAM.get_mask","text":"Create a mask from a set of points.\n\nEach point defines a circular region that is used to avoid detecting features in that region.\n\nCircular regions are filled with zero(T) values, while the rest of the mask is has ones(T) values.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.in_image-Tuple{Camera, Any}","page":"API Reference","title":"SLAM.in_image","text":"Check if point is in the image bounds of the Camera.\n\nArguments:\n\npoint: Point to check. In (y, x) format.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.is_bad!-Tuple{SLAM.MapPoint}","page":"API Reference","title":"SLAM.is_bad!","text":"Check if MapPoint is bad and update it if so.\n\nBad MapPoint is a 3D point that is observed by < 2 KeyFrames and not observed by current Frame (e.g. m.observed = false). If bad, set is_3d to false.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.local_bundle_adjustment!-Tuple{SLAM.Estimator, SLAM.Frame}","page":"API Reference","title":"SLAM.local_bundle_adjustment!","text":"Perform Bundle-Adjustment on the new frame and its covisibility graph.\n\nMinimize error function over all KeyFrame's extrinsic parameters in the covisibility graph and their corresponding MapPoint's positions. Afterwards, update these parameters.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.map_filtering!-Tuple{SLAM.Estimator, SLAM.Frame}","page":"API Reference","title":"SLAM.map_filtering!","text":"Filter out KeyFrames that share too many MapPoints with other KeyFrames in the covisibility graph. Since they are not informative.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.match_local_map!-Tuple{SLAM.Mapper, SLAM.Frame}","page":"API Reference","title":"SLAM.match_local_map!","text":"Try matching keypoints from frame with keypoints from frames in its covisibility graph (aka local map).\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.project-Tuple{Camera, Any}","page":"API Reference","title":"SLAM.project","text":"Project point from 3D space onto the image plane.\n\nArguments:\n\npoint: Point in 3D space in (x, y, z) format.\n\nReturns:\n\nProjected point in (y, x) format.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.project_undistort-Tuple{Camera, Any}","page":"API Reference","title":"SLAM.project_undistort","text":"Project point onto image plane of the Camera, accounting for the distortion parameters of the camera.\n\nArguments:\n\npoint: 3D point to project in (x, y, z) format.\n\nReturns:\n\n2D floating point coordinates in (y, x) format.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.remove_mappoint!-Tuple{SLAM.MapManager, Any}","page":"API Reference","title":"SLAM.remove_mappoint!","text":"Remove MapPoint from the map given its id.\n\nRemoving a mappoint, also update covisibility scores of the observer Frames. If MapPoint is observed by the current Frame, remove its keypoint as well.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.remove_mappoint_obs!-Tuple{SLAM.MapManager, Int64, Int64}","page":"API Reference","title":"SLAM.remove_mappoint_obs!","text":"Remove KeyFrame observation from MapPoint.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.remove_obs_from_current_frame!-Tuple{SLAM.MapManager, Int64}","page":"API Reference","title":"SLAM.remove_obs_from_current_frame!","text":"Remove a MapPoint observation from current Frame by id.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.to_cartesian-Tuple{Any}","page":"API Reference","title":"SLAM.to_cartesian","text":"Params:     x::Point2 Point to convert to CartesianIndex in (row, col) format.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.track!-Tuple{SLAM.FrontEnd, Any, Any}","page":"API Reference","title":"SLAM.track!","text":"Given an image and time at which it was taken, track keypoints in it. After tracking, decide if the system needs a new Keyframe added to the map. If it is the first image to be tracked, then Keyframe is always needed.\n\nReturns:\n\ntrue if the system needs a new Keyframe, otherwise false.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.undistort_pdn_point-Tuple{Camera, Any}","page":"API Reference","title":"SLAM.undistort_pdn_point","text":"Undistort point.\n\nArguments:\n\npoint::SVector{2}: Predivided by K & normalized point in (y, x) format.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.undistort_point-Tuple{Camera, StaticArrays.SVector{2, T} where T}","page":"API Reference","title":"SLAM.undistort_point","text":"Arguments:\n\npoint::SVector{2}: Point to undistort. In (y, x) format.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.update_frame_covisibility!-Tuple{SLAM.MapManager, SLAM.Frame}","page":"API Reference","title":"SLAM.update_frame_covisibility!","text":"Update MapPoints and covisible graph between KeyFrames.\n\n\n\n\n\n","category":"method"},{"location":"api.html#SLAM.update_mappoint!-Tuple{SLAM.MapManager, Any, Any}","page":"API Reference","title":"SLAM.update_mappoint!","text":"Update position of a MapPoint.\n\n\n\n\n\n","category":"method"},{"location":"index.html#SLAM.jl","page":"Home","title":"SLAM.jl","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Simultaneous Localization and Mapping.","category":"page"},{"location":"index.html#Features:","page":"Home","title":"Features:","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Monocular / Stereo modes.\nBundle-Adjustment over a subset of Keyframes.\nLocal Map Matching for re-tracking lost Mappoints back into Frame.","category":"page"},{"location":"index.html#Results","page":"Home","title":"Results","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Final map on the 00 sequence taken from KITTY dataset in stereo mode.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"(Image: KITTY 00 sequence)","category":"page"}]
}
